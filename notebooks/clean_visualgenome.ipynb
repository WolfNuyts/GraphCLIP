{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108077/108077 [00:17<00:00, 6163.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "LOCAL_DATA_PATH = '/local/home/jthomm/GraphCLIP/datasets/visual_genome/'\n",
    "import json\n",
    "# you need to download the scene graph data from visual genome, it's not included in dario's folder (and i don't have write access there)\n",
    "with open(LOCAL_DATA_PATH+'raw/scene_graphs.json', 'r') as f:\n",
    "    scene_graphs_dict = json.load(f)\n",
    "\n",
    "def build_graph(g_dict):\n",
    "        G = nx.DiGraph()\n",
    "        G.image_id=g_dict['image_id']\n",
    "        G.labels = {}\n",
    "        for obj in g_dict['objects']:\n",
    "            G.add_node(obj['object_id'], w=obj['w'], h=obj['h'], x=obj['x'], y=obj['y'], attributes=obj.get('attributes',[]), name=obj['names'][0])\n",
    "            G.labels[obj['object_id']] = obj['names'][0]\n",
    "        for rel in g_dict['relationships']:\n",
    "            G.add_edge(rel['subject_id'], rel['object_id'], synsets=rel['synsets'] ,relationship_id=rel['relationship_id'], predicate=rel['predicate'])\n",
    "        return G\n",
    "graphs = [] \n",
    "for g_dict in tqdm(scene_graphs_dict):\n",
    "    graphs.append(build_graph(g_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108077/108077 [00:13<00:00, 8179.54it/s] \n"
     ]
    }
   ],
   "source": [
    "# convert all object labels, attributes and predicates to lower case and remove trailing spaces\n",
    "for g in tqdm(graphs):\n",
    "    for n in g.nodes:\n",
    "        g.nodes[n]['name'] = g.nodes[n]['name'].lower().strip()\n",
    "        g.nodes[n]['attributes'] = [a.lower().strip() for a in g.nodes[n]['attributes']]\n",
    "    for e in g.edges:\n",
    "        g.edges[e]['predicate'] = g.edges[e]['predicate'].lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of graphs: 108077\n",
      "number of object labels: 100298\n",
      "number of relationship labels: 34459\n",
      "number of attribute labels: 65557\n"
     ]
    }
   ],
   "source": [
    "# extract all object labels and all relationship labels and all attribute labels from the graphs\n",
    "object_labels = {}\n",
    "relationship_labels = {}\n",
    "attribute_labels = {}\n",
    "for g in graphs:\n",
    "    for obj_label in g.labels.values():\n",
    "        # # remove trailing spaces\n",
    "        # obj_label = obj_label.strip().lower()\n",
    "        object_labels[obj_label] = object_labels.get(obj_label, 0) + 1\n",
    "    for rel_label in [g.edges[e]['predicate'] for e in g.edges]:\n",
    "        # rel_label = rel_label.strip().lower()\n",
    "        relationship_labels[rel_label] = relationship_labels.get(rel_label, 0) + 1\n",
    "    for attr_label in [g.nodes[n]['attributes'] for n in g.nodes]:\n",
    "        for a in attr_label:\n",
    "            # a = a.strip().lower()\n",
    "            attribute_labels[a] = attribute_labels.get(a, 0) + 1\n",
    "print(f'number of graphs: {len(graphs)}')\n",
    "print(f'number of object labels: {len(object_labels)}')\n",
    "print(f'number of relationship labels: {len(relationship_labels)}')\n",
    "print(f'number of attribute labels: {len(attribute_labels)}')\n",
    "# sort the labels for both the objects and relationships and extract the 100 most frequent ones in the graphs\n",
    "object_labels_occurrences = sorted(object_labels.items(), key=lambda x: x[1], reverse=True)[:200]\n",
    "relationship_labels_occurrences = sorted(relationship_labels.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "attribute_labels_occurrences = sorted(attribute_labels.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "# extract the labels from the tuples\n",
    "object_labels = [l[0] for l in object_labels_occurrences]\n",
    "relationship_labels = [l[0] for l in relationship_labels_occurrences]\n",
    "attribute_labels = [l[0] for l in attribute_labels_occurrences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man', 'person', 'window', 'tree', 'building', 'shirt', 'wall', 'woman', 'sign', 'sky', 'ground', 'grass', 'table', 'pole', 'head', 'light', 'water', 'car', 'hand', 'hair', 'people', 'leg', 'trees', 'clouds', 'ear', 'plate', 'leaves', 'fence', 'door', 'pants', 'eye', 'train', 'chair', 'floor', 'road', 'street', 'hat', 'snow', 'wheel', 'shadow', 'jacket', 'nose', 'boy', 'line', 'shoe', 'clock', 'sidewalk', 'boat', 'tail', 'cloud', 'handle', 'letter', 'girl', 'leaf', 'horse', 'bus', 'helmet', 'bird', 'giraffe', 'field', 'plane', 'flower', 'elephant', 'umbrella', 'dog', 'shorts', 'arm', 'zebra', 'face', 'windows', 'sheep', 'glass', 'bag', 'cow', 'bench', 'cat', 'food', 'bottle', 'rock', 'tile', 'kite', 'tire', 'post', 'number', 'stripe', 'surfboard', 'truck', 'logo', 'glasses', 'roof', 'skateboard', 'motorcycle', 'picture', 'flowers', 'bear', 'player', 'foot', 'bowl', 'mirror', 'background', 'pizza', 'bike', 'shoes', 'spot', 'tracks', 'pillow', 'shelf', 'cap', 'mouth', 'box', 'jeans', 'dirt', 'lights', 'legs', 'house', 'part', 'trunk', 'banana', 'top', 'plant', 'cup', 'counter', 'board', 'bed', 'wave', 'bush', 'ball', 'sink', 'button', 'lamp', 'beach', 'brick', 'flag', 'neck', 'sand', 'vase', 'writing', 'wing', 'paper', 'seat', 'lines', 'reflection', 'coat', 'child', 'toilet', 'laptop', 'airplane', 'letters', 'glove', 'vehicle', 'phone', 'book', 'branch', 'sunglasses', 'edge', 'cake', 'desk', 'rocks', 'frisbee', 'tie', 'tower', 'animal', 'hill', 'mountain', 'headlight', 'ceiling', 'cabinet', 'eyes', 'stripes', 'wheels', 'lady', 'ocean', 'racket', 'container', 'skier', 'keyboard', 'towel', 'frame', 'windshield', 'hands', 'back', 'track', 'bat', 'finger', 'pot', 'orange', 'fork', 'waves', 'design', 'feet', 'basket', 'fruit', 'broccoli', 'engine', 'guy', 'knife', 'couch', 'railing', 'collar', 'cars']\n",
      "['on', 'has', 'in', 'of', 'wearing', 'with', 'behind', 'holding', 'on a', 'near', 'on top of', 'next to', 'has a', 'under', 'of a', 'by', 'above', 'wears', 'in front of', 'sitting on', 'on side of', 'attached to', 'wearing a', 'in a', 'over', 'are on', 'at', 'for', 'around', 'beside', 'standing on', 'riding', 'standing in', 'inside', 'have', 'hanging on', 'walking on', 'on front of', 'are in', 'hanging from', 'carrying', 'holds', 'covering', 'belonging to', 'between', 'along', 'eating', 'and', 'sitting in', 'watching', 'below', 'painted on', 'laying on', 'against', 'playing', 'from', 'inside of', 'looking at', 'with a', 'parked on', 'to', 'has an', 'made of', 'covered in', 'mounted on', 'says', 'growing on', 'across', 'part of', 'on back of', 'flying in', 'outside', 'lying on', 'worn by', 'walking in', 'sitting at', 'printed on', 'underneath', 'crossing', 'beneath', 'full of', 'using', 'filled with', 'hanging in', 'covered with', 'built into', 'standing next to', 'adorning', 'a', 'in middle of', 'flying', 'supporting', 'touching', 'next', 'swinging', 'pulling', 'growing in', 'sitting on top of', 'standing', 'lying on top of']\n",
      "['white', 'black', 'blue', 'green', 'red', 'brown', 'yellow', 'small', 'large', 'wooden', 'gray', 'silver', 'metal', 'orange', 'grey', 'tall', 'long', 'dark', 'pink', 'clear', 'standing', 'round', 'tan', 'glass', 'here', 'wood', 'open', 'purple', 'big', 'short', 'plastic', 'parked', 'sitting', 'walking', 'striped', 'brick', 'young', 'gold', 'old', 'hanging', 'empty', 'on', 'bright', 'concrete', 'cloudy', 'colorful', 'one', 'beige', 'bare', 'wet', 'light', 'square', 'little', 'closed', 'stone', 'blonde', 'shiny', 'thin', 'dirty', 'flying', 'smiling', 'painted', 'thick', 'part', 'sliced', 'playing', 'tennis', 'calm', 'leather', 'distant', 'rectangular', 'looking', 'grassy', 'dry', 'light brown', 'cement', 'leafy', 'wearing', 'tiled', \"man's\", 'light blue', 'baseball', 'cooked', 'pictured', 'curved', 'decorative', 'dead', 'eating', 'paper', 'paved', 'fluffy', 'lit', 'back', 'framed', 'plaid', 'dirt', 'watching', 'colored', 'stuffed', 'circular']\n"
     ]
    }
   ],
   "source": [
    "print(object_labels)\n",
    "print(relationship_labels)\n",
    "print(attribute_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': 79, 'h': 339, 'x': 421, 'y': 91, 'attributes': ['green', 'tall'], 'name': 'clock'}\n",
      "{'synsets': ['along.r.01'], 'relationship_id': 15927, 'predicate': 'on'}\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0].nodes[list(graphs[0].nodes)[0]])\n",
    "print(graphs[0].edges[list(graphs[0].edges)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108077/108077 [00:24<00:00, 4434.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_filtered_graph(g, object_labels, relationship_labels, attribute_labels):\n",
    "        G = nx.DiGraph()\n",
    "        G.image_id=g.image_id\n",
    "        G.labels = {}\n",
    "        for n in g.nodes:\n",
    "            if g.labels[n] in object_labels:\n",
    "                filtered_attributes = [a for a in g.nodes[n]['attributes'] if a in attribute_labels]\n",
    "                G.add_node(n, w=g.nodes[n]['w'], h=g.nodes[n]['h'], x=g.nodes[n]['x'], y=g.nodes[n]['y'], attributes=filtered_attributes, name=g.labels[n])\n",
    "                G.labels[n] = g.labels[n]\n",
    "        for e in g.edges:\n",
    "            if g.edges[e]['predicate'] in relationship_labels and e[0] in G.nodes and e[1] in G.nodes:\n",
    "                G.add_edge(e[0], e[1], synsets=g.edges[e]['synsets'].copy() ,relationship_id=g.edges[e]['relationship_id'], predicate=g.edges[e]['predicate'])\n",
    "        return G\n",
    "\n",
    "# filter the graphs relationships and objects and attributes to only keep the 100/200 most frequent ones. Remove graphs which have no objects or relationships left after filtering\n",
    "filtered_graphs = []\n",
    "for g in tqdm(graphs):\n",
    "    g_filtered = build_filtered_graph(g, object_labels, relationship_labels, attribute_labels)\n",
    "    if len(g_filtered.nodes) > 0 and len(g_filtered.edges) > 0:\n",
    "        filtered_graphs.append(g_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of graphs: 97216\n",
      "number of objects: 2204832\n",
      "number of relationships: 776509\n",
      "number of attributes: 1001979\n"
     ]
    }
   ],
   "source": [
    "# print the graphs stats: number of graphs, number of objects, number of relationships, number of attributes\n",
    "print(f'number of graphs: {len(filtered_graphs)}')\n",
    "print(f'number of objects: {sum([len(g.nodes) for g in filtered_graphs])}')\n",
    "print(f'number of relationships: {sum([len(g.edges) for g in filtered_graphs])}')\n",
    "print(f'number of attributes: {sum([len(g.nodes[n][\"attributes\"]) for g in filtered_graphs for n in g.nodes])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0].image_id)\n",
    "print(filtered_graphs[0].image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/jthomm/anaconda3/envs/jtpython2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:1')\n",
    "from open_clip import create_model_and_transforms\n",
    "model,preprocess, _ = create_model_and_transforms('ViT-bigG-14', pretrained='laion2b_s39b_b160k', device=device) # the biggest model available\n",
    "from open_clip import get_tokenizer\n",
    "tokenizer = get_tokenizer(model_name='ViT-bigG-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man', 'a person']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 34.32it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "labels_to_embed = [\"a \"+ l for l in object_labels]\n",
    "chunked_object_labels = [labels_to_embed[i:i + batch_size] for i in range(0, len(labels_to_embed), batch_size)]\n",
    "obj_label_embeddings = []\n",
    "print(chunked_object_labels[0])\n",
    "for i, chunk in enumerate(tqdm(chunked_object_labels)):\n",
    "    chunk = tokenizer(chunk).to(device)\n",
    "    emd_chunk = model.encode_text(chunk).detach().cpu().numpy()\n",
    "    for s in emd_chunk:\n",
    "        obj_label_embeddings.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1280)\n"
     ]
    }
   ],
   "source": [
    "# encode a radom astronaut image\n",
    "from skimage import data\n",
    "from PIL import Image\n",
    "img = data.astronaut()\n",
    "img_preprocessed = preprocess(Image.fromarray(img)).unsqueeze(0).to(device)\n",
    "with torch.cuda.amp.autocast():\n",
    "    img_embedding = model.encode_image(img_preprocessed).detach().cpu().numpy()\n",
    "print(img_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: \n",
      "[334.43994] (for a man)\n",
      "[346.87274] (for a person)\n",
      "[283.4137] (for a window)\n",
      "[260.72723] (for a tree)\n"
     ]
    }
   ],
   "source": [
    "choice1 = obj_label_embeddings[0]\n",
    "choice2 = obj_label_embeddings[1]\n",
    "choice3 = obj_label_embeddings[2]\n",
    "choice4 = obj_label_embeddings[3]\n",
    "print(\"similarities: \")\n",
    "print(img_embedding @ choice1.T, f\"(for {labels_to_embed[0]})\")\n",
    "print(img_embedding @ choice2.T, f\"(for {labels_to_embed[1]})\")\n",
    "print(img_embedding @ choice3.T, f\"(for {labels_to_embed[2]})\")\n",
    "print(img_embedding @ choice4.T, f\"(for {labels_to_embed[3]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the filtered graphs with torch.save\n",
    "import torch\n",
    "torch.save(filtered_graphs, LOCAL_DATA_PATH+'processed/filtered_graphs.pt')\n",
    "torch.save(filtered_graphs[0:100], LOCAL_DATA_PATH+'processed/filtered_graphs_test_small.pt')\n",
    "torch.save(object_labels, LOCAL_DATA_PATH+'processed/filtered_object_labels.pt')\n",
    "torch.save(obj_label_embeddings, LOCAL_DATA_PATH+'processed/filtered_object_label_embeddings.pt')\n",
    "torch.save(relationship_labels, LOCAL_DATA_PATH+'processed/filtered_relationship_labels.pt')\n",
    "torch.save(attribute_labels, LOCAL_DATA_PATH+'processed/filtered_attribute_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(g):\n",
    "    pos = nx.nx_agraph.graphviz_layout(g, prog=\"dot\")\n",
    "    max_y = max([y for x,y in pos.values()])\n",
    "    n_nodes_top = len([n for n in g.nodes if pos[n][1] == max_y])\n",
    "    longest_label = max([len(g.labels[n]) for n in g.nodes])\n",
    "    plt.figure(figsize=(max(n_nodes_top*longest_label/10,15),5))\n",
    "    nx.draw(g,pos=pos,labels=g.labels, with_labels=True, node_size=10, node_color=\"lightgray\", font_size=8)\n",
    "    nx.draw_networkx_edge_labels(g,pos=pos,edge_labels=nx.get_edge_attributes(g,'predicate'),font_size=8)\n",
    "    plt.show()\n",
    "print(f'there are now {len(filtered_graphs)} many graphs left')\n",
    "print(f'example graph:')\n",
    "import random\n",
    "idx = random.randint(0,len(filtered_graphs))\n",
    "plot_graph(filtered_graphs[idx])\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jtpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
