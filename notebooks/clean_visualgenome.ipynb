{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import io\n",
    "from PIL import Image\n",
    "LOCAL_DATA_PATH = '/local/home/jthomm/GraphCLIP/datasets/visual_genome/'\n",
    "import json\n",
    "# you need to download the scene graph data from visual genome, it's not included in dario's folder (and i don't have write access there)\n",
    "with open(LOCAL_DATA_PATH+'raw/scene_graphs.json', 'r') as f:\n",
    "    scene_graphs_dict = json.load(f)\n",
    "\n",
    "def build_graph(g_dict):\n",
    "        G = nx.DiGraph()\n",
    "        G.image_id=g_dict['image_id']\n",
    "        with open(LOCAL_DATA_PATH+'raw/VG/'+str(G.image_id)+'.jpg', 'rb') as f:\n",
    "            image_bytes = f.read()\n",
    "            s = Image.open(io.BytesIO(image_bytes)).size\n",
    "            G.image_w = s[0]\n",
    "            G.image_h = s[1]\n",
    "        G.labels = {}\n",
    "        for obj in g_dict['objects']:\n",
    "            G.add_node(obj['object_id'], w=obj['w'], h=obj['h'], x=obj['x'], y=obj['y'], attributes=obj.get('attributes',[]), name=obj['names'][0])\n",
    "            G.labels[obj['object_id']] = obj['names'][0]\n",
    "        for rel in g_dict['relationships']:\n",
    "            G.add_edge(rel['subject_id'], rel['object_id'], synsets=rel['synsets'] ,relationship_id=rel['relationship_id'], predicate=rel['predicate'])\n",
    "        return G\n",
    "graphs = [] \n",
    "for g_dict in tqdm(scene_graphs_dict):\n",
    "    graphs.append(build_graph(g_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108077/108077 [00:15<00:00, 6927.48it/s] \n"
     ]
    }
   ],
   "source": [
    "# convert all object labels, attributes and predicates to lower case and remove trailing spaces\n",
    "for g in tqdm(graphs):\n",
    "    for n in g.nodes:\n",
    "        g.nodes[n]['name'] = g.nodes[n]['name'].lower().strip()\n",
    "        g.nodes[n]['attributes'] = [a.lower().strip() for a in g.nodes[n]['attributes']]\n",
    "    for e in g.edges:\n",
    "        g.edges[e]['predicate'] = g.edges[e]['predicate'].lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of graphs: 108077\n",
      "number of object labels: 100298\n",
      "number of relationship labels: 34459\n",
      "number of attribute labels: 65557\n"
     ]
    }
   ],
   "source": [
    "# extract all object labels and all relationship labels and all attribute labels from the graphs\n",
    "object_labels = {}\n",
    "relationship_labels = {}\n",
    "attribute_labels = {}\n",
    "for g in graphs:\n",
    "    for obj_label in g.labels.values():\n",
    "        # # remove trailing spaces\n",
    "        # obj_label = obj_label.strip().lower()\n",
    "        object_labels[obj_label] = object_labels.get(obj_label, 0) + 1\n",
    "    for rel_label in [g.edges[e]['predicate'] for e in g.edges]:\n",
    "        # rel_label = rel_label.strip().lower()\n",
    "        relationship_labels[rel_label] = relationship_labels.get(rel_label, 0) + 1\n",
    "    for attr_label in [g.nodes[n]['attributes'] for n in g.nodes]:\n",
    "        for a in attr_label:\n",
    "            # a = a.strip().lower()\n",
    "            attribute_labels[a] = attribute_labels.get(a, 0) + 1\n",
    "print(f'number of graphs: {len(graphs)}')\n",
    "print(f'number of object labels: {len(object_labels)}')\n",
    "print(f'number of relationship labels: {len(relationship_labels)}')\n",
    "print(f'number of attribute labels: {len(attribute_labels)}')\n",
    "# sort the labels for both the objects and relationships and extract the 100 most frequent ones in the graphs\n",
    "object_labels_occurrences = sorted(object_labels.items(), key=lambda x: x[1], reverse=True)[:200]\n",
    "relationship_labels_occurrences = sorted(relationship_labels.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "attribute_labels_occurrences = sorted(attribute_labels.items(), key=lambda x: x[1], reverse=True)[:100]\n",
    "# extract the labels from the tuples\n",
    "object_labels = [l[0] for l in object_labels_occurrences]\n",
    "relationship_labels = [l[0] for l in relationship_labels_occurrences]\n",
    "attribute_labels = [l[0] for l in attribute_labels_occurrences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man', 'person', 'window', 'tree', 'building', 'shirt', 'wall', 'woman', 'sign', 'sky', 'ground', 'grass', 'table', 'pole', 'head', 'light', 'water', 'car', 'hand', 'hair', 'people', 'leg', 'trees', 'clouds', 'ear', 'plate', 'leaves', 'fence', 'door', 'pants', 'eye', 'train', 'chair', 'floor', 'road', 'street', 'hat', 'snow', 'wheel', 'shadow', 'jacket', 'nose', 'boy', 'line', 'shoe', 'clock', 'sidewalk', 'boat', 'tail', 'cloud', 'handle', 'letter', 'girl', 'leaf', 'horse', 'bus', 'helmet', 'bird', 'giraffe', 'field', 'plane', 'flower', 'elephant', 'umbrella', 'dog', 'shorts', 'arm', 'zebra', 'face', 'windows', 'sheep', 'glass', 'bag', 'cow', 'bench', 'cat', 'food', 'bottle', 'rock', 'tile', 'kite', 'tire', 'post', 'number', 'stripe', 'surfboard', 'truck', 'logo', 'glasses', 'roof', 'skateboard', 'motorcycle', 'picture', 'flowers', 'bear', 'player', 'foot', 'bowl', 'mirror', 'background', 'pizza', 'bike', 'shoes', 'spot', 'tracks', 'pillow', 'shelf', 'cap', 'mouth', 'box', 'jeans', 'dirt', 'lights', 'legs', 'house', 'part', 'trunk', 'banana', 'top', 'plant', 'cup', 'counter', 'board', 'bed', 'wave', 'bush', 'ball', 'sink', 'button', 'lamp', 'beach', 'brick', 'flag', 'neck', 'sand', 'vase', 'writing', 'wing', 'paper', 'seat', 'lines', 'reflection', 'coat', 'child', 'toilet', 'laptop', 'airplane', 'letters', 'glove', 'vehicle', 'phone', 'book', 'branch', 'sunglasses', 'edge', 'cake', 'desk', 'rocks', 'frisbee', 'tie', 'tower', 'animal', 'hill', 'mountain', 'headlight', 'ceiling', 'cabinet', 'eyes', 'stripes', 'wheels', 'lady', 'ocean', 'racket', 'container', 'skier', 'keyboard', 'towel', 'frame', 'windshield', 'hands', 'back', 'track', 'bat', 'finger', 'pot', 'orange', 'fork', 'waves', 'design', 'feet', 'basket', 'fruit', 'broccoli', 'engine', 'guy', 'knife', 'couch', 'railing', 'collar', 'cars']\n",
      "['on', 'has', 'in', 'of', 'wearing', 'with', 'behind', 'holding', 'on a', 'near', 'on top of', 'next to', 'has a', 'under', 'of a', 'by', 'above', 'wears', 'in front of', 'sitting on', 'on side of', 'attached to', 'wearing a', 'in a', 'over', 'are on', 'at', 'for', 'around', 'beside', 'standing on', 'riding', 'standing in', 'inside', 'have', 'hanging on', 'walking on', 'on front of', 'are in', 'hanging from', 'carrying', 'holds', 'covering', 'belonging to', 'between', 'along', 'eating', 'and', 'sitting in', 'watching', 'below', 'painted on', 'laying on', 'against', 'playing', 'from', 'inside of', 'looking at', 'with a', 'parked on', 'to', 'has an', 'made of', 'covered in', 'mounted on', 'says', 'growing on', 'across', 'part of', 'on back of', 'flying in', 'outside', 'lying on', 'worn by', 'walking in', 'sitting at', 'printed on', 'underneath', 'crossing', 'beneath', 'full of', 'using', 'filled with', 'hanging in', 'covered with', 'built into', 'standing next to', 'adorning', 'a', 'in middle of', 'flying', 'supporting', 'touching', 'next', 'swinging', 'pulling', 'growing in', 'sitting on top of', 'standing', 'lying on top of']\n",
      "['white', 'black', 'blue', 'green', 'red', 'brown', 'yellow', 'small', 'large', 'wooden', 'gray', 'silver', 'metal', 'orange', 'grey', 'tall', 'long', 'dark', 'pink', 'clear', 'standing', 'round', 'tan', 'glass', 'here', 'wood', 'open', 'purple', 'big', 'short', 'plastic', 'parked', 'sitting', 'walking', 'striped', 'brick', 'young', 'gold', 'old', 'hanging', 'empty', 'on', 'bright', 'concrete', 'cloudy', 'colorful', 'one', 'beige', 'bare', 'wet', 'light', 'square', 'little', 'closed', 'stone', 'blonde', 'shiny', 'thin', 'dirty', 'flying', 'smiling', 'painted', 'thick', 'part', 'sliced', 'playing', 'tennis', 'calm', 'leather', 'distant', 'rectangular', 'looking', 'grassy', 'dry', 'light brown', 'cement', 'leafy', 'wearing', 'tiled', \"man's\", 'light blue', 'baseball', 'cooked', 'pictured', 'curved', 'decorative', 'dead', 'eating', 'paper', 'paved', 'fluffy', 'lit', 'back', 'framed', 'plaid', 'dirt', 'watching', 'colored', 'stuffed', 'circular']\n"
     ]
    }
   ],
   "source": [
    "print(object_labels)\n",
    "print(relationship_labels)\n",
    "print(attribute_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': 79, 'h': 339, 'x': 421, 'y': 91, 'attributes': ['green', 'tall'], 'name': 'clock'}\n",
      "{'synsets': ['along.r.01'], 'relationship_id': 15927, 'predicate': 'on'}\n"
     ]
    }
   ],
   "source": [
    "print(graphs[0].nodes[list(graphs[0].nodes)[0]])\n",
    "print(graphs[0].edges[list(graphs[0].edges)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108077/108077 [00:18<00:00, 5842.15it/s]\n"
     ]
    }
   ],
   "source": [
    "def build_filtered_graph(g, object_labels, relationship_labels, attribute_labels):\n",
    "        G = nx.DiGraph()\n",
    "        G.image_id=g.image_id\n",
    "        G.image_w = g.image_w\n",
    "        G.image_h = g.image_h\n",
    "        G.labels = {}\n",
    "        for n in g.nodes:\n",
    "            if g.labels[n] in object_labels:\n",
    "                filtered_attributes = [a for a in g.nodes[n]['attributes'] if a in attribute_labels]\n",
    "                G.add_node(n, w=g.nodes[n]['w'], h=g.nodes[n]['h'], x=g.nodes[n]['x'], y=g.nodes[n]['y'], attributes=filtered_attributes, name=g.labels[n])\n",
    "                G.labels[n] = g.labels[n]\n",
    "        for e in g.edges:\n",
    "            if g.edges[e]['predicate'] in relationship_labels and e[0] in G.nodes and e[1] in G.nodes:\n",
    "                G.add_edge(e[0], e[1], synsets=g.edges[e]['synsets'].copy() ,relationship_id=g.edges[e]['relationship_id'], predicate=g.edges[e]['predicate'])\n",
    "        return G\n",
    "\n",
    "# filter the graphs relationships and objects and attributes to only keep the 100/200 most frequent ones. Remove graphs which have no objects or relationships left after filtering\n",
    "filtered_graphs = []\n",
    "for g in tqdm(graphs):\n",
    "    g_filtered = build_filtered_graph(g, object_labels, relationship_labels, attribute_labels)\n",
    "    if len(g_filtered.nodes) > 0 and len(g_filtered.edges) > 0:\n",
    "        filtered_graphs.append(g_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of graphs: 97216\n",
      "number of objects: 2204832\n",
      "number of relationships: 776509\n",
      "number of attributes: 1001979\n"
     ]
    }
   ],
   "source": [
    "# print the graphs stats: number of graphs, number of objects, number of relationships, number of attributes\n",
    "print(f'number of graphs: {len(filtered_graphs)}')\n",
    "print(f'number of objects: {sum([len(g.nodes) for g in filtered_graphs])}')\n",
    "print(f'number of relationships: {sum([len(g.edges) for g in filtered_graphs])}')\n",
    "print(f'number of attributes: {sum([len(g.nodes[n][\"attributes\"]) for g in filtered_graphs for n in g.nodes])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:1')\n",
    "from open_clip import create_model_and_transforms\n",
    "model,preprocess, _ = create_model_and_transforms('ViT-bigG-14', pretrained='laion2b_s39b_b160k', device=device) # the biggest model available\n",
    "from open_clip import get_tokenizer\n",
    "tokenizer = get_tokenizer(model_name='ViT-bigG-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a man', 'a person']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 34.32it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "labels_to_embed = [\"a \"+ l for l in object_labels]\n",
    "chunked_object_labels = [labels_to_embed[i:i + batch_size] for i in range(0, len(labels_to_embed), batch_size)]\n",
    "obj_label_embeddings = []\n",
    "print(chunked_object_labels[0])\n",
    "for i, chunk in enumerate(tqdm(chunked_object_labels)):\n",
    "    chunk = tokenizer(chunk).to(device)\n",
    "    emd_chunk = model.encode_text(chunk).detach().cpu().numpy()\n",
    "    for s in emd_chunk:\n",
    "        obj_label_embeddings.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1280)\n"
     ]
    }
   ],
   "source": [
    "# encode a radom astronaut image\n",
    "from skimage import data\n",
    "from PIL import Image\n",
    "img = data.astronaut()\n",
    "img_preprocessed = preprocess(Image.fromarray(img)).unsqueeze(0).to(device)\n",
    "with torch.cuda.amp.autocast():\n",
    "    img_embedding = model.encode_image(img_preprocessed).detach().cpu().numpy()\n",
    "print(img_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: \n",
      "[334.43994] (for a man)\n",
      "[346.87274] (for a person)\n",
      "[283.4137] (for a window)\n",
      "[260.72723] (for a tree)\n"
     ]
    }
   ],
   "source": [
    "choice1 = obj_label_embeddings[0]\n",
    "choice2 = obj_label_embeddings[1]\n",
    "choice3 = obj_label_embeddings[2]\n",
    "choice4 = obj_label_embeddings[3]\n",
    "print(\"similarities: \")\n",
    "print(img_embedding @ choice1.T, f\"(for {labels_to_embed[0]})\")\n",
    "print(img_embedding @ choice2.T, f\"(for {labels_to_embed[1]})\")\n",
    "print(img_embedding @ choice3.T, f\"(for {labels_to_embed[2]})\")\n",
    "print(img_embedding @ choice4.T, f\"(for {labels_to_embed[3]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the filtered graphs with torch.save\n",
    "import torch\n",
    "torch.save(filtered_graphs, LOCAL_DATA_PATH+'processed/filtered_graphs.pt')\n",
    "torch.save(filtered_graphs[0:100], LOCAL_DATA_PATH+'processed/filtered_graphs_test_small.pt')\n",
    "torch.save(object_labels, LOCAL_DATA_PATH+'processed/filtered_object_labels.pt')\n",
    "torch.save(obj_label_embeddings, LOCAL_DATA_PATH+'processed/filtered_object_label_embeddings.pt')\n",
    "torch.save(relationship_labels, LOCAL_DATA_PATH+'processed/filtered_relationship_labels.pt')\n",
    "torch.save(attribute_labels, LOCAL_DATA_PATH+'processed/filtered_attribute_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(g):\n",
    "    pos = nx.nx_agraph.graphviz_layout(g, prog=\"dot\")\n",
    "    max_y = max([y for x,y in pos.values()])\n",
    "    n_nodes_top = len([n for n in g.nodes if pos[n][1] == max_y])\n",
    "    longest_label = max([len(g.labels[n]) for n in g.nodes])\n",
    "    plt.figure(figsize=(max(n_nodes_top*longest_label/10,15),5))\n",
    "    nx.draw(g,pos=pos,labels=g.labels, with_labels=True, node_size=10, node_color=\"lightgray\", font_size=8)\n",
    "    nx.draw_networkx_edge_labels(g,pos=pos,edge_labels=nx.get_edge_attributes(g,'predicate'),font_size=8)\n",
    "    plt.show()\n",
    "print(f'there are now {len(filtered_graphs)} many graphs left')\n",
    "print(f'example graph:')\n",
    "import random\n",
    "idx = random.randint(0,len(filtered_graphs))\n",
    "plot_graph(filtered_graphs[idx])\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small script to clean the adversarial dataset attributes (don't run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "(<networkx.classes.digraph.DiGraph object at 0x7f007886f8b0>, (1058686, 5989), 'lying on')\n",
      "removed attribute  wide\n",
      "removed attribute  pedestrian line\n",
      "removed attribute  faded\n",
      "removed attribute  sunny\n",
      "removed attribute  wide\n",
      "removed attribute  pedestrian line\n",
      "removed attribute  faded\n",
      "removed attribute  sunny\n",
      "removed attribute  carpeted\n",
      "removed attribute  clean\n",
      "removed attribute  dry erase board\n",
      "removed attribute  cardboard\n",
      "removed attribute  cardboard\n",
      "removed attribute  folded\n",
      "removed attribute  greenish\n",
      "removed attribute  cork\n",
      "removed attribute  full\n",
      "removed attribute  folded\n",
      "removed attribute  greenish\n",
      "removed attribute  cork\n",
      "removed attribute  full\n",
      "removed attribute  folded\n",
      "removed attribute  greenish\n",
      "removed attribute  cork\n",
      "removed attribute  full\n",
      "removed attribute  balding\n",
      "removed attribute  bald\n",
      "removed attribute  floral\n",
      "removed attribute  printed\n",
      "removed attribute  white haired\n",
      "removed attribute  gray haired\n",
      "removed attribute  steel gray\n",
      "removed attribute  covered\n",
      "removed attribute  balding\n",
      "removed attribute  bald\n",
      "removed attribute  floral\n",
      "removed attribute  printed\n",
      "removed attribute  white haired\n",
      "removed attribute  gray haired\n",
      "removed attribute  steel gray\n",
      "removed attribute  covered\n",
      "removed attribute  balding\n",
      "removed attribute  bald\n",
      "removed attribute  floral\n",
      "removed attribute  printed\n",
      "removed attribute  white haired\n",
      "removed attribute  gray haired\n",
      "removed attribute  steel gray\n",
      "removed attribute  covered\n",
      "removed attribute  balding\n",
      "removed attribute  bald\n",
      "removed attribute  floral\n",
      "removed attribute  printed\n",
      "removed attribute  white haired\n",
      "removed attribute  gray haired\n",
      "removed attribute  steel gray\n",
      "removed attribute  covered\n",
      "removed attribute  man\n",
      "removed attribute  woman\n",
      "removed attribute  khaki\n",
      "removed attribute  off\n",
      "removed attribute  off\n",
      "removed attribute  off\n",
      "removed attribute  off\n",
      "removed attribute  white computer\n",
      "removed attribute  modernistic\n",
      "removed attribute  on edge\n",
      "removed attribute  white computer\n",
      "removed attribute  modernistic\n",
      "removed attribute  on edge\n",
      "removed attribute  for flower\n",
      "removed attribute  hardwood\n",
      "removed attribute  floor\n",
      "removed attribute  floor\n",
      "removed attribute  circuluar\n",
      "removed attribute  locker style\n",
      "removed attribute  tufted\n",
      "removed attribute  floor lamp\n",
      "removed attribute  chrome\n",
      "removed attribute  gold framed\n",
      "removed attribute  gold framed\n",
      "removed attribute  gold framed\n",
      "removed attribute  gold framed\n",
      "removed attribute  gold framed\n",
      "removed attribute  gold framed\n",
      "removed attribute  gold framed\n",
      "removed attribute  cardboard\n",
      "removed attribute  clean\n",
      "removed attribute  cardboard\n",
      "removed attribute  clean\n",
      "removed attribute  cardboard\n",
      "removed attribute  clean\n",
      "removed attribute  cardboard\n",
      "removed attribute  clean\n",
      "removed attribute  row\n",
      "removed attribute  skiing\n",
      "removed attribute  skiing\n",
      "removed attribute  snowy\n",
      "removed attribute  held\n",
      "removed attribute  uncomfortable\n",
      "removed attribute  uncomfortable\n",
      "removed attribute  light green\n",
      "removed attribute  light green\n",
      "removed attribute  dell\n",
      "removed attribute  intel\n",
      "removed attribute  windows\n",
      "removed attribute  carpeted\n",
      "removed attribute  carpeted\n",
      "removed attribute  grazing\n",
      "removed attribute  plentiful\n",
      "removed attribute  wine glass\n",
      "removed attribute  squinting\n",
      "removed attribute  trying\n",
      "removed attribute  older\n",
      "removed attribute  happy\n",
      "removed attribute  finished\n",
      "removed attribute  happy\n",
      "removed attribute  finished\n",
      "removed attribute  wine glass\n",
      "removed attribute  wine glass\n",
      "removed attribute  meeting\n",
      "removed attribute  meeting\n",
      "removed attribute  balding\n",
      "removed attribute  wine glass\n",
      "removed attribute  squinting\n",
      "removed attribute  trying\n",
      "removed attribute  older\n",
      "removed attribute  happy\n",
      "removed attribute  finished\n",
      "removed attribute  happy\n",
      "removed attribute  finished\n",
      "removed attribute  wine glass\n",
      "removed attribute  wine glass\n",
      "removed attribute  meeting\n",
      "removed attribute  meeting\n",
      "removed attribute  balding\n",
      "removed attribute  grazing\n",
      "removed attribute  grazing\n",
      "removed attribute  laying\n",
      "removed attribute  grazing\n",
      "removed attribute  grazing\n",
      "removed attribute  laying\n",
      "removed attribute  grazing\n",
      "removed attribute  grazing\n",
      "removed attribute  laying\n",
      "removed attribute  grazing\n",
      "removed attribute  grazing\n",
      "removed attribute  laying\n",
      "removed attribute  stop\n",
      "removed attribute  stop sign\n",
      "removed attribute  stop\n",
      "removed attribute  stop sign\n",
      "removed attribute  body\n",
      "removed attribute  kicked up\n",
      "removed attribute  in front\n",
      "removed attribute  splash\n",
      "removed attribute  behind\n",
      "removed attribute  talking\n",
      "removed attribute  talking\n",
      "removed attribute  talking\n",
      "removed attribute  talking\n",
      "removed attribute  talking\n",
      "removed attribute  talking\n",
      "removed attribute  talking\n",
      "removed attribute  talking\n",
      "removed attribute  octagonal\n",
      "removed attribute  sandy\n",
      "removed attribute  nice\n",
      "removed attribute  american\n",
      "removed attribute  driving\n",
      "removed attribute  octagonal\n",
      "removed attribute  sandy\n",
      "removed attribute  nice\n",
      "removed attribute  american\n",
      "removed attribute  driving\n",
      "removed attribute  octagonal\n",
      "removed attribute  sandy\n",
      "removed attribute  nice\n",
      "removed attribute  american\n",
      "removed attribute  driving\n",
      "removed attribute  octagonal\n",
      "removed attribute  sandy\n",
      "removed attribute  nice\n",
      "removed attribute  american\n",
      "removed attribute  driving\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  many\n",
      "removed attribute  into mischief\n",
      "removed attribute  near house\n",
      "removed attribute  having fun\n",
      "removed attribute  enjoying day\n",
      "removed attribute  speckled\n",
      "removed attribute  into mischief\n",
      "removed attribute  near house\n",
      "removed attribute  having fun\n",
      "removed attribute  enjoying day\n",
      "removed attribute  speckled\n",
      "removed attribute  lite\n",
      "removed attribute  group\n",
      "removed attribute  group\n",
      "removed attribute  beautiful view\n",
      "removed attribute  group\n",
      "removed attribute  wood framed\n",
      "removed attribute  switched on\n",
      "removed attribute  black rimmed\n",
      "removed attribute  potted\n",
      "removed attribute  oval\n",
      "removed attribute  running\n",
      "removed attribute  running\n",
      "removed attribute  shallow\n",
      "removed attribute  oval\n",
      "removed attribute  low to ground\n",
      "removed attribute  reflection\n",
      "removed attribute  bidet\n",
      "removed attribute  three-way\n",
      "removed attribute  fake\n",
      "removed attribute  fake\n",
      "removed attribute  ice covered\n",
      "removed attribute  snowy\n",
      "removed attribute  white-capped\n",
      "removed attribute  snow-capped\n",
      "removed attribute  danger\n",
      "removed attribute  warning\n",
      "removed attribute  symbol\n",
      "removed attribute  cracked\n",
      "removed attribute  alone\n",
      "removed attribute  greyish blue\n",
      "removed attribute  darker\n",
      "removed attribute  puffy\n",
      "removed attribute  ice covered\n",
      "removed attribute  snowy\n",
      "removed attribute  white-capped\n",
      "removed attribute  snow-capped\n",
      "removed attribute  danger\n",
      "removed attribute  warning\n",
      "removed attribute  symbol\n",
      "removed attribute  cracked\n",
      "removed attribute  alone\n",
      "removed attribute  greyish blue\n",
      "removed attribute  darker\n",
      "removed attribute  puffy\n",
      "removed attribute  cream\n",
      "removed attribute  cream\n",
      "removed attribute  cream\n",
      "removed attribute  dark green\n",
      "removed attribute  cargo\n",
      "removed attribute  reds\n",
      "removed attribute  nike\n",
      "removed attribute  flat\n",
      "removed attribute  athletic\n",
      "removed attribute  dark green\n",
      "removed attribute  cargo\n",
      "removed attribute  reds\n",
      "removed attribute  nike\n",
      "removed attribute  flat\n",
      "removed attribute  athletic\n",
      "removed attribute  multiple\n",
      "removed attribute  landing\n",
      "removed attribute  horizontal\n",
      "removed attribute  bringing passengers\n",
      "removed attribute  landed\n",
      "removed attribute  taking off\n",
      "removed attribute  taking off\n",
      "removed attribute  jet aircraft\n",
      "removed attribute  operating\n",
      "removed attribute  multicolored\n",
      "removed attribute  rainbow\n",
      "removed attribute  tatty\n",
      "removed attribute  turned up\n",
      "removed attribute  off\n",
      "removed attribute  waiting\n",
      "removed attribute  narrow\n",
      "removed attribute  paneled\n",
      "removed attribute  rain-covered\n",
      "removed attribute  multicolored\n",
      "removed attribute  rainbow\n",
      "removed attribute  tatty\n",
      "removed attribute  turned up\n",
      "removed attribute  off\n",
      "removed attribute  waiting\n",
      "removed attribute  narrow\n",
      "removed attribute  paneled\n",
      "removed attribute  rain-covered\n",
      "removed attribute  multicolored\n",
      "removed attribute  rainbow\n",
      "removed attribute  tatty\n",
      "removed attribute  turned up\n",
      "removed attribute  off\n",
      "removed attribute  waiting\n",
      "removed attribute  narrow\n",
      "removed attribute  paneled\n",
      "removed attribute  rain-covered\n",
      "removed attribute  is black\n",
      "removed attribute  socked\n",
      "removed attribute  resin\n",
      "removed attribute  resin\n",
      "removed attribute  resin\n",
      "removed attribute  resin\n",
      "removed attribute  resin\n",
      "removed attribute  resin\n",
      "removed attribute  resin\n",
      "removed attribute  multi section\n",
      "removed attribute  post\n",
      "removed attribute  black and white\n",
      "removed attribute  sign\n",
      "removed attribute  sign\n",
      "removed attribute  holding something up\n",
      "removed attribute  beige/tan\n",
      "removed attribute  arch type\n",
      "removed attribute  gree\n",
      "removed attribute  turf\n",
      "removed attribute  gree\n",
      "removed attribute  turf\n",
      "removed 321 attributes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "path = '/local/home/jthomm/GraphCLIP/datasets/visual_genome/processed/ra_selections_curated_adversarial_nofilteredattr.pt'\n",
    "ra_selections = torch.load(path)\n",
    "print(len(ra_selections))\n",
    "print(ra_selections[0])\n",
    "new_selections = []\n",
    "n_removed_attributes = 0\n",
    "for sel in ra_selections:\n",
    "    original_graph = sel[0]\n",
    "    new_graph = build_filtered_graph(sel[0], object_labels, relationship_labels, attribute_labels)\n",
    "    new_selections.append((new_graph, sel[1], sel[2]))\n",
    "    for n in original_graph.nodes:\n",
    "        if n not in new_graph.nodes:\n",
    "            assert False # this should not happen\n",
    "        for a in original_graph.nodes[n]['attributes']:\n",
    "            if a not in new_graph.nodes[n]['attributes']:\n",
    "                print(\"removed attribute \", a)\n",
    "                n_removed_attributes += 1\n",
    "        for a in new_graph.nodes[n]['attributes']:\n",
    "            if a not in original_graph.nodes[n]['attributes']:\n",
    "                assert False # this should not happen\n",
    "    for e in original_graph.edges:\n",
    "        if e not in new_graph.edges:\n",
    "            assert False\n",
    "print(f\"removed {n_removed_attributes} attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_selections, '/local/home/jthomm/GraphCLIP/datasets/visual_genome/processed/ra_selections_curated_adversarial.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jtpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
