{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Stable Diffusion with `rige`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import relational_image_generation_evaluation as rige"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:1 for evaluation.\n"
     ]
    }
   ],
   "source": [
    "EVALUATOR_NAME = \"GraphCLIP\"\n",
    "evaluator = rige.Evaluator(EVALUATOR_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filtered test graphs...\n",
      "Finished loading filtered test graphs\n",
      "Generating one edge graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1164.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating one edge graphs\n",
      "len(dataloader): 837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testonly => ~1000 samples subset for testing purposes, not full evaluation\n",
    "dataloader = rige.get_one_edge_dataloader(shuffle=False, testonly=True)\n",
    "print(\"len(dataloader):\", len(dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Stable Diffusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.0+cu118 with CUDA 1108 (you have 1.13.0+cu117)\n",
      "    Python  3.10.11 (you have 3.10.9)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from relational_image_generation_evaluation.vision_transformer.jt_training import get_free_gpu\n",
    "\n",
    "# First model\n",
    "model_id1 = \"runwayml/stable-diffusion-v1-5\"\n",
    "name1 = \"SD 1.5\"\n",
    "pipe1 = StableDiffusionPipeline.from_pretrained(model_id1, safety_checker=None, torch_dtype=torch.float16)\n",
    "pipe1 = pipe1.to(get_free_gpu(min_mem=21_000))\n",
    "def txt2img1(txt):\n",
    "    return pipe1(txt).images[0]\n",
    "\n",
    "# Second model\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "name2 = \"SD 2.1\"\n",
    "pipe2 = StableDiffusionPipeline.from_pretrained(model_id, safety_checker=None, torch_dtype=torch.float16)\n",
    "pipe2 = pipe2.to(get_free_gpu(min_mem=21_000))\n",
    "\n",
    "def txt2img2(txt):\n",
    "    return pipe2(txt).images[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run interactive evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize lists that collect users votes and evaluator scores. Generate images and score them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e259306ce98b4bd5a67b6bd3d40bc9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 145.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19cedfe1f5a450094fdf1dc0282fa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 150.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from itertools import islice\n",
    "\n",
    "imgs = {\n",
    "    name1: [],\n",
    "    name2: [],\n",
    "}\n",
    "votes = []\n",
    "scores = {\n",
    "    name1: [],\n",
    "    name2: [],\n",
    "}\n",
    "captions = []\n",
    "N_SAMPLES_TO_EVALUATE = 4\n",
    "d_iter = iter(dataloader)\n",
    "d_iter = islice(d_iter, N_SAMPLES_TO_EVALUATE)\n",
    "\n",
    "labeled_functions = [(txt2img1, name1), (txt2img2, name2)]\n",
    "\n",
    "def score_image(img, sample):\n",
    "    scores = evaluator([img],[sample])\n",
    "    return scores['overall_scores'][0]\n",
    "\n",
    "for idx, sample in enumerate(d_iter):\n",
    "    captions.append(sample[0].caption)\n",
    "    assert len(sample) == 1\n",
    "    clear_output(wait=False)\n",
    "    for func, label in labeled_functions:\n",
    "        print(f\"{idx}/{N_SAMPLES_TO_EVALUATE}\")\n",
    "        img = func(sample[0].caption)  # Generate the image with the function\n",
    "        score = score_image(img, sample[0])\n",
    "        scores[label].append(score)\n",
    "        imgs[label].append(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display images and vote on them manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3: man wearing brown shoes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Generator: SD 1.5    Score: 4.437'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4026806/739994583.py:34: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  img = img.resize((base_width, h_size), Image.ANTIALIAS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Generator: SD 2.1    Score: 5.617'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b9f02662394f9596c02522ce4bb4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01,\\x00\\x00\\x01,\\x08\\x02\\x00\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6511dbb8944a5181f9abc5f9aa069b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='First better', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1945d8de2f45748693ff97aaf1f03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Second better', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11dd4673f024e2e8a4dfb48853eb735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Equally good', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe10e6965ff4c8a959b72cf4d3004f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Pause', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as display\n",
    "from ipywidgets import widgets, HBox\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    pause = False\n",
    "    if b.description == 'Pause':\n",
    "        pause = True\n",
    "    else:\n",
    "        votes.append(b.description)\n",
    "    if pause:\n",
    "        print(\"Pausing\")\n",
    "    else:\n",
    "        if len(votes) == len(captions):\n",
    "            print(\"Done!\")\n",
    "        else:\n",
    "            process()\n",
    "\n",
    "def process():\n",
    "    display.clear_output(wait=True)\n",
    "    print(f\"Sample {len(votes)}: {captions[len(votes)]}\")\n",
    "    # Display each function's image with corresponding label\n",
    "    resized_images = []\n",
    "    for _, label in labeled_functions:\n",
    "        img = imgs[label][len(votes)]  # Generate the image with the function\n",
    "        score = scores[label][len(votes)]\n",
    "        display.display(f\"Generator: {label}    Score: {score:.3f}\")\n",
    "        # Resize the image\n",
    "        base_width = 300  # Define the width to resize to\n",
    "        w_percent = (base_width / float(img.size[0]))\n",
    "        h_size = int((float(img.size[1]) * float(w_percent)))\n",
    "        img = img.resize((base_width, h_size), Image.ANTIALIAS)\n",
    "\n",
    "        # Convert PIL Image to a format that IPython Image can render\n",
    "        byte_arr = io.BytesIO()\n",
    "        img.save(byte_arr, format='PNG')\n",
    "        byte_arr.seek(0)\n",
    "        \n",
    "        resized_images.append(byte_arr)\n",
    "    hbox = HBox([widgets.Image(value=resized_image.getvalue(), format='png') for resized_image in resized_images])\n",
    "    display.display(hbox)\n",
    "\n",
    "    # Display the buttons\n",
    "    button_options = [\"First better\", \"Second better\", \"Equally good\", \"Pause\"]\n",
    "    for option in button_options:\n",
    "        button = widgets.Button(description=option)\n",
    "        button.on_click(on_button_clicked)\n",
    "        display.display(button)\n",
    "\n",
    "# Start the process\n",
    "process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jonathan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
