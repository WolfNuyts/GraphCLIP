model = "GraphCLIP"
dataset = "VisualGenome"
seed = 123456
device = "cuda:0"
type = "train"

[model_args]
architecture = "GNN8"
[model_args.arch_args]
in_dim = 2048
out_dim = 1024
edge_dim = 2048
middle_dim = 512
p_dropout = 0.4
model_name = "ViT-g-14"
pretrained = "laion2b_s12b_b42k"
freeze_embedding = true
embedding_init = "CLIP"

[train_args]
epochs = 100
batch_size = 128
learning_rate = 0.001
train_val_split = "mscoco"
epochs_per_checkpoint = 0.38
load_checkpoint_path = ""

[dataset_args]
root = "datasets/visual_genome"
n_samples = "all"
transform = "add_master_node_with_bidirectional_edges"
use_long_rel_enc = true
[dataset_args.enc_cfg]
model_name = "ViT-g-14"
pretrained = "laion2b_s12b_b42k"
use_clip_latents = false
device = "cuda:0"

[dataset_filter_args]
filters = ["remove_edgeless_graphs"]
[valset_filter_args]
filters = ["remove_visualgenome_duplicates"]